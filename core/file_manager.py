# -*- coding: utf-8 -*-
"""
File Manager Module
Handles saving generated content to markdown files
"""

from pathlib import Path
from datetime import datetime
from typing import Dict, Optional


def get_temperature_description_hebrew(temperature: float) -> str:
    """Get Hebrew description of temperature setting"""
    if temperature <= 0.3:
        return "砖专转 (转专 注拽 拽)"
    elif temperature <= 0.5:
        return "转 (  拽 爪专转转)"
    elif temperature <= 0.7:
        return "爪专转转 ( 住驻转)"
    else:
        return "爪专转转  (注 驻转注)"


def save_markdown_output(
    product: str,
    persona: str,
    strategy_output: str,
    copy_output: str,
    execution_time: float,
    rag_summary: Dict,
    temperature: float,
    inputs: Dict,
    token_usage: Optional[Dict] = None
) -> str:
    """
    Save generated content to markdown file with metadata.

    Args:
        product: Product name
        persona: Selected persona
        strategy_output: Strategy architect output
        copy_output: Copywriter output
        execution_time: Total execution time in seconds
        rag_summary: RAG query summary
        temperature: Temperature setting
        inputs: Original campaign inputs
        token_usage: Optional token usage statistics

    Returns:
        Path to saved file
    """
    try:
        # Create outputs directory
        output_dir = Path("outputs")
        output_dir.mkdir(exist_ok=True)

        # Generate filename with timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_product = "".join(c for c in product if c.isalnum() or c in (' ', '-', '_')).strip()[:50]
        filename = f"{timestamp}_{safe_product}_{persona.replace(' ', '_')}.md"
        filepath = output_dir / filename

        # Get persona details
        persona_description = ""
        search_terms_display = ""

        # Get persona-specific search terms and description from config
        try:
            from config import PersonaConfig
            if persona in PersonaConfig.PERSONA_SEARCH_TERMS:
                terms = PersonaConfig.PERSONA_SEARCH_TERMS[persona]
                tone_terms = ', '.join(terms.get('tone', []))
                style_terms = ', '.join(terms.get('style', []))
                search_terms_display = f"""** 驻砖 砖注砖 砖砖 :**
- ** (Tone):** {tone_terms}
- **住 (Style):** {style_terms}
"""

                # Get persona description
                persona_descriptions = {
                    "Professional Dana": " 拽爪注 拽, -专, 砖 转注转 注转, 住 砖 转 砖转转 (Thought Leadership)",
                    "Friendly Dana": " 专转 砖转, 拽 砖 '专  ', 住驻专 砖, 拽'  拽爪注",
                    "Inspirational Dana": "爪 注爪, 住专 砖驻转, 专 专砖, 驻拽住 注 专住驻专爪",
                    "Mentor Dana": "  , 注爪转 转转, 砖 转, 转 驻转"
                }
                persona_description = persona_descriptions.get(persona, "")
        except (ImportError, AttributeError, KeyError) as e:
            # ImportError: config module not available
            # AttributeError: PersonaConfig not in config
            # KeyError: persona not in PERSONA_SEARCH_TERMS
            pass

        # Format temperature
        temp_hebrew = get_temperature_description_hebrew(temperature)
        temperature_display = f"**专转 爪专转转:** {temp_hebrew} (Temperature: {temperature})\n"

        # Format execution time
        minutes = int(execution_time // 60)
        seconds = execution_time % 60
        if minutes > 0:
            exec_time_display = f"** 爪注:** {minutes} 拽转 -{seconds:.1f} 砖转 ({execution_time:.1f} 砖转 住\")\n"
        else:
            exec_time_display = f"** 爪注:** {execution_time:.1f} 砖转\n"

        # Format RAG summary
        rag_display = ""
        if rag_summary:
            total_queries = rag_summary.get('total_queries', 0)
            rag_display = f"**驻砖 RAG:** {total_queries}\n"

        # Format token usage
        token_display = ""
        if token_usage:
            # Handle both dict and UsageMetrics object
            if hasattr(token_usage, 'get'):
                # It's a dict
                total_tokens = token_usage.get('total_tokens', 0)
                prompt_tokens = token_usage.get('prompt_tokens', 0)
                completion_tokens = token_usage.get('completion_tokens', 0)
                total_cost = token_usage.get('total_cost_usd', 0)
            else:
                # It's a UsageMetrics object
                total_tokens = getattr(token_usage, 'total_tokens', 0)
                prompt_tokens = getattr(token_usage, 'prompt_tokens', 0)
                completion_tokens = getattr(token_usage, 'completion_tokens', 0)
                total_cost = getattr(token_usage, 'total_cost', 0)

            token_display = f"""**砖砖 拽:**
- Input: {prompt_tokens:,}
- Output: {completion_tokens:,}
- 住": {total_tokens:,}
- 注转: ${total_cost:.4f}

"""

        # Combined output (use copy_output as the main content)
        combined_output = copy_output if copy_output else "(no content generated)"

        # Format markdown content
        md_content = f"""# 转 砖拽 - Dana's Brain

**爪专 转专:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**爪专:** {product}
**驻专住:** {persona}

---

##  -转 注 驻拽转 转

{temperature_display}{exec_time_display}{rag_display}{token_display}**住驻专 驻住 砖爪专:** 9 (3 LinkedIn + 3 Facebook + 3 Instagram)
**专 注:** 5 拽爪 注 砖  (转, 转 转, 驻专 住, 驻专 驻驻专转, 专驻)

---

##  转 驻专住 砖专

**{persona}** - {persona_description}

{search_terms_display}
---

##  转拽爪专 住专 (Campaign Bible)

{strategy_output}

---

## 锔 驻住  专转转

{combined_output}

---

##  注专转 砖砖

- **注转拽 专:**  驻住 住 驻驻专 砖 (LinkedIn/Facebook/Instagram)
- **注专:** 转 注专 转 驻住 转 爪专 住驻爪驻
- **驻专住:**  驻住 转 驻专  砖 驻驻专 砖

---

** 爪专 注  Dana's Brain** - 注专转 AI 爪专 转 砖拽
驻注 爪注转 Streamlit + CrewAI 注 RAG (Retrieval-Augmented Generation)
"""

        # Write to file with UTF-8 encoding (for Hebrew)
        filepath.write_text(md_content, encoding='utf-8')

        return str(filepath)

    except Exception as e:
        raise Exception(f"Failed to save markdown file: {str(e)}")
